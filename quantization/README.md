# Quantization for Large Language Models (LLMs)

## ðŸ“– Comprehensive Quantization Guide
For the most complete, up-to-date, and professional reference on quantization for LLMs, see:

ðŸ‘‰ [Comprehensive Quantization Guide for Large Language Models (LLMs)](quantization_guide.md)

This document merges the best of DataCamp, Hugging Face, and QLoRA resources, covering:
- Theory and motivation
- Data types and precision
- All quantization methods (static, dynamic, PTQ, QAT, binary/ternary)
- Advanced techniques (QLoRA, GPTQ, GGUF, BitNet)
- Practical usage with Hugging Face Transformers
- Benchmarks, visuals, and best practices
- Further reading and references

## Quickstart
If you want to get started right away, see the [Practical Usage](quantization_guide.md#8-practical-usage-hugging-face-transformers--bitsandbytes) section in the comprehensive guide.

---

For legacy or original blog content, see [quantisation_original.md](quantisation_original.md). 