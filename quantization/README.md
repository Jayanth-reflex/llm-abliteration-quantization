# Quantization for Large Language Models (LLMs)

## ðŸ“– The Golden Resource
For the most comprehensive, up-to-date, and professional guide on quantization for LLMs, see:

ðŸ‘‰ [The Golden Resource: Quantization for Large Language Models (LLMs)](quantization_golden_resource.md)

This document merges the best of DataCamp, Hugging Face, and QLoRA resources, covering:
- Theory and motivation
- Data types and precision
- All quantization methods (static, dynamic, PTQ, QAT, binary/ternary)
- Advanced techniques (QLoRA, GPTQ, GGUF, BitNet)
- Practical usage with Hugging Face Transformers
- Benchmarks, visuals, and best practices
- Further reading and references

## Quickstart
If you want to get started right away, see the [Practical Usage](quantization_golden_resource.md#8-practical-usage-hugging-face-transformers--bitsandbytes) section in the golden resource.

---

For legacy or original blog content, see [quantisation_original.md](quantisation_original.md). 